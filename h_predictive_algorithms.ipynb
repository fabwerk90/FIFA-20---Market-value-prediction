{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T15:41:59.013687Z",
     "start_time": "2020-05-05T15:41:57.870346Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T15:41:59.230079Z",
     "start_time": "2020-05-05T15:41:59.015653Z"
    }
   },
   "outputs": [],
   "source": [
    "df_fp = pd.read_csv(\"data/fp_data_final.csv\", index_col=0)\n",
    "df_gk = pd.read_csv(\"data/gk_data_final.csv\", index_col=0)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T15:41:59.238058Z",
     "start_time": "2020-05-05T15:41:59.233071Z"
    }
   },
   "outputs": [],
   "source": [
    "# set random seed for all algos\n",
    "rseed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T15:41:59.250025Z",
     "start_time": "2020-05-05T15:41:59.241050Z"
    }
   },
   "outputs": [],
   "source": [
    "# suppress scientific notation\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare datasets for prediction | general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T15:41:59.267979Z",
     "start_time": "2020-05-05T15:41:59.252021Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop irrelevant rows\n",
    "\n",
    "df_fp = df_fp.drop([\"player_name\",\"long_name\",\"year_of_birth\",\"height_cm\",\"weight_kg\",\"nationality\",\"club\"],axis=1)\n",
    "\n",
    "df_gk = df_gk.drop([\"player_name\",\"long_name\",\"year_of_birth\",\"height_cm\",\"weight_kg\",\"nationality\",\"club\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vorgehensweise\n",
    "1. Für finalen Test --> Test-Set wegpacken\n",
    "2. Mit train_set train-test-split und predicten\n",
    "3. Final mit test_set_final predicten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T15:41:59.291914Z",
     "start_time": "2020-05-05T15:41:59.269974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fieldplayers: \n",
      "(8598, 54)\n",
      "(2149,)\n",
      "-----------------------\n",
      "Goalkeepers: \n",
      "(1110, 37)\n",
      "(277,)\n"
     ]
    }
   ],
   "source": [
    "# 1. put final test set aside\n",
    "\n",
    "# fieldplayers\n",
    "train_set_fp = df_fp.sample(frac=0.80, random_state=rseed)\n",
    "y_final_fp = df_fp.drop(train_set_fp.index)\n",
    "y_final_fp = y_final_fp[\"market_value_in_euro\"]\n",
    "\n",
    "# goal keepers\n",
    "train_set_gk = df_gk.sample(frac=0.80, random_state=rseed)\n",
    "y_final_gk = df_gk.drop(train_set_gk.index)\n",
    "y_final_gk = y_final_gk[\"market_value_in_euro\"]\n",
    "\n",
    "print(\"Fieldplayers: \")\n",
    "print(train_set_fp.shape)\n",
    "print(y_final_fp.shape)\n",
    "print(\"-----------------------\")\n",
    "print(\"Goalkeepers: \")\n",
    "print(train_set_gk.shape)\n",
    "print(y_final_gk.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify best models \n",
    "\n",
    "Regressors to be used:\n",
    "1. Linear Regression\n",
    "6. Stochastic Gradient Descent\n",
    "7. Decision Trees\n",
    "8. Random Forest\n",
    "9. AdaBoost\n",
    "10. Gradient Tree Boosting\n",
    "11. XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T15:59:17.780223Z",
     "start_time": "2020-05-05T15:59:17.765234Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def model_selection (train_set):\n",
    "\n",
    "    ###################################\n",
    "    # 2.1. train-test-split with remaining 80% of data\n",
    "    ###################################\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X = train_set.drop([\"market_value_in_euro\"],axis=1)\n",
    "\n",
    "    y = train_set[\"market_value_in_euro\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rseed)\n",
    "\n",
    "    ###################################\n",
    "    # 2.2. Build preprocessing pipeline with\n",
    "    # - standard scaler\n",
    "    # - onehotencoder\n",
    "    ###################################\n",
    "\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    ###################################\n",
    "    # 2.3. Apply column transformer\n",
    "    ###################################\n",
    "\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "\n",
    "    numeric_features = train_set.select_dtypes(include=['int64', 'float64']).drop([\"market_value_in_euro\"],axis=1).columns\n",
    "    categorical_features = train_set.select_dtypes(include=['object']).columns\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "    ###################################\n",
    "    # 2.4. Fit algorithms\n",
    "    ###################################\n",
    "\n",
    "    from sklearn import linear_model\n",
    "    from sklearn import svm\n",
    "    from sklearn import tree\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.ensemble import AdaBoostRegressor\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    import xgboost as xgb\n",
    "    \n",
    "\n",
    "    models = []\n",
    "    models.append((\"LR\",linear_model.LinearRegression()))\n",
    "    models.append((\"SGD\",linear_model.SGDRegressor(random_state=rseed)))\n",
    "    models.append((\"DT\",tree.DecisionTreeRegressor(random_state=rseed)))\n",
    "    models.append((\"RF\",RandomForestRegressor(random_state=rseed,n_jobs=-1)))\n",
    "    models.append((\"ADA\",AdaBoostRegressor(random_state=rseed)))\n",
    "    models.append((\"GDB\",GradientBoostingRegressor(random_state=rseed)))\n",
    "    models.append((\"XGB\",xgb.XGBRegressor(random_state=rseed)))\n",
    "    \n",
    "\n",
    "    results = []\n",
    "    names = []\n",
    "    scoring = 'neg_root_mean_squared_error'\n",
    "    \n",
    "    for name,regressor in models:\n",
    "        pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('regressor', regressor)])\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = pipe.predict(X_test)\n",
    "    \n",
    "        ###################################\n",
    "        # 2.5. Calculate comparison metric (MRSE) and visualize comparison\n",
    "        ###################################\n",
    "\n",
    "        from sklearn.metrics import mean_squared_error\n",
    "        \n",
    "        import math\n",
    "        from math import sqrt\n",
    "        \n",
    "        from sklearn import model_selection\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "\n",
    "        \n",
    "        \n",
    "        kfold = model_selection.KFold(n_splits=5, random_state=rseed, shuffle=True)\n",
    "        cv_results = abs(model_selection.cross_val_score(pipe, X, y, cv=kfold, scoring=scoring))\n",
    "        cv_mean = math.ceil(cv_results.mean())\n",
    "        cv_std = math.ceil(cv_results.std())\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        print(f\"{name}: \", f\"{cv_mean:0,}\", f\"({cv_std:0,})\")\n",
    "\n",
    "    # boxplot algorithm comparison\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle('Algorithm Comparison')\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.boxplot(results)\n",
    "    ax.set_xticklabels(names)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T16:00:51.918389Z",
     "start_time": "2020-05-05T15:59:18.834653Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:  2,518,939 (81,314)\n",
      "SGD:  2,524,106 (81,601)\n",
      "DT:  2,696,631 (136,046)\n",
      "RF:  1,934,319 (90,223)\n",
      "ADA:  3,953,392 (205,402)\n",
      "GDB:  1,878,969 (121,475)\n",
      "[18:00:43] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabian\\Anaconda3\\envs\\nf\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\Fabian\\Anaconda3\\envs\\nf\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:00:44] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabian\\Anaconda3\\envs\\nf\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:00:46] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabian\\Anaconda3\\envs\\nf\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:00:47] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabian\\Anaconda3\\envs\\nf\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:00:49] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabian\\Anaconda3\\envs\\nf\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:00:50] WARNING: src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "XGB:  1,858,716 (120,307)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_selection (train_set_fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### --> best 3 algorithms are Random Forests, GDBoost and XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T16:49:30.875663Z",
     "start_time": "2020-05-05T16:49:30.851723Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def best_algos_pipeline (train_set):\n",
    "\n",
    "    ###################################\n",
    "    # 2.1. train-test-split with remaining 80% of data\n",
    "    ###################################\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X = train_set.drop([\"market_value_in_euro\"],axis=1)\n",
    "\n",
    "    y = train_set[\"market_value_in_euro\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rseed)\n",
    "\n",
    "    ###################################\n",
    "    # 2.2. Build preprocessing pipeline with\n",
    "    # - a scaler for numerical columns\n",
    "    # - an encoder for categorical columns\n",
    "    ###################################\n",
    "\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('scaler', StandardScaler())])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    ###################################\n",
    "    # 2.3. Apply column transformer\n",
    "    ###################################\n",
    "\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "\n",
    "    numeric_features = train_set.select_dtypes(include=['int64', 'float64']).drop([\"market_value_in_euro\"],axis=1).columns\n",
    "    categorical_features = train_set.select_dtypes(include=['object']).columns\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "    ###################################\n",
    "    # 2.4. Fit algorithms\n",
    "    ###################################\n",
    "\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.ensemble import GradientBoostingRegressor\n",
    "    import xgboost as xgb\n",
    "    \n",
    "\n",
    "    models = []\n",
    "    models.append((\"Random Forest\",RandomForestRegressor(random_state=rseed,n_jobs=-1)))\n",
    "    models.append((\"Gradient Boost\",GradientBoostingRegressor(random_state=rseed)))\n",
    "    models.append((\"XGBoost\",xgb.XGBRegressor(random_state=rseed)))\n",
    "    \n",
    "\n",
    "    \n",
    "    for name,regressor in models:\n",
    "        pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('regressor', regressor)])\n",
    "        \n",
    "        param_grid = {\n",
    "            'regressor__n_estimators': [200, 500],\n",
    "            'regressor__max_features': ['auto', 'sqrt', 'log2'],\n",
    "            'regressor__max_depth' : [4,5,6,7,8],}\n",
    "        \n",
    "        from sklearn.model_selection import GridSearchCV\n",
    "        \n",
    "        CV = GridSearchCV(pipe, param_grid, n_jobs= 1)\n",
    "        CV.fit(X_train, y_train)  \n",
    "        \n",
    "        y_pred = CV.predict(X_test)\n",
    "    \n",
    "        ###################################\n",
    "        # 2.5. Calculate following metrics for each model with simple train-test-split and with cv\n",
    "        # a. MSE\n",
    "        # b. MRSE\n",
    "        # c. MAE\n",
    "        # d. R²\n",
    "        # e. Adjusted R²\n",
    "        ###################################\n",
    "\n",
    "        from sklearn.metrics import mean_squared_error\n",
    "        from sklearn.metrics import mean_absolute_error\n",
    "        from sklearn.metrics import r2_score\n",
    "        \n",
    "        import math\n",
    "        from math import sqrt\n",
    "        \n",
    "        from sklearn import model_selection\n",
    "        from sklearn.model_selection import cross_val_score\n",
    "        \n",
    "        \n",
    "        kfold = model_selection.KFold(n_splits=5, random_state=rseed, shuffle=True)\n",
    "        \n",
    "        # a\n",
    "        mse = math.ceil(mean_squared_error(y_test, y_pred))\n",
    "        cv_mse = cross_val_score(pipe, X, y, cv=kfold, scoring=\"neg_mean_squared_error\",n_jobs=-1)\n",
    "        cv_mse_mean = math.ceil(abs(cv_mse.mean()))\n",
    "       \n",
    "        # b\n",
    "        mrse = math.ceil(sqrt(mse))\n",
    "        cv_mrse = cross_val_score(pipe, X, y, cv=kfold, scoring=\"neg_root_mean_squared_error\",n_jobs=-1)\n",
    "        cv_mrse_mean = math.ceil(abs(cv_mrse.mean()))\n",
    "        \n",
    "        # c\n",
    "        mae = math.ceil(mean_absolute_error(y_test, y_pred))\n",
    "        cv_mae = cross_val_score(pipe, X, y, cv=kfold, scoring=\"neg_mean_absolute_error\",n_jobs=-1)\n",
    "        cv_mae_mean = math.ceil(abs(cv_mae.mean()))\n",
    "        \n",
    "        # d\n",
    "        r_squared = round(r2_score(y_test, y_pred),3)\n",
    "        cv_r_squared = cross_val_score(pipe, X, y, cv=kfold, scoring=\"r2\",n_jobs=-1)\n",
    "        cv_r_squared_mean = round((cv_r_squared.mean()),3)\n",
    "        \n",
    "        # e\n",
    "        n = train_set.shape[0]\n",
    "        p = len(train_set.columns)\n",
    "        adjusted_r_squared = round((1-(1-r_squared)*(n-1)/(n-p-1)),3)\n",
    "        cv_adjusted_r_squared = round((1-(1-cv_r_squared_mean)*(n-1)/(n-p-1)),3)\n",
    "        \n",
    "        ###################################\n",
    "        # 2.6. Print results\n",
    "        ###################################\n",
    "      \n",
    "          \n",
    "        from prettytable import PrettyTable\n",
    "        ptable = PrettyTable()\n",
    "\n",
    "        ptable.field_names = [\"Metric\", \"Score on test set\", \"Score on test set with 5 k-fold CV \"]\n",
    "        ptable.add_row([\"MSE\",f\"{mse:0,}\",f\"{cv_mse_mean:0,}\"])\n",
    "        ptable.add_row([\"MRSE\",f\"{mrse:0,}\",f\"{cv_mrse_mean:0,}\"])\n",
    "        ptable.add_row([\"MAE\",f\"{mae:0,}\",f\"{cv_mae_mean:0,}\"])\n",
    "        ptable.add_row([\"r_squared\",r_squared,cv_r_squared_mean])\n",
    "        ptable.add_row([\"adjusted_r_squared\",adjusted_r_squared,cv_adjusted_r_squared])\n",
    "        \n",
    "        print(\"----------------------------------------------------------------------------------------------------------\")\n",
    "        print(\"\\033[1m\",name,\"\\033[0m\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------------\")\n",
    "        print (ptable)\n",
    "        ###################################\n",
    "        # 2.5. Print results\n",
    "        ###################################\n",
    "        from yellowbrick.regressor import residuals_plot\n",
    "        from yellowbrick.datasets import load_concrete\n",
    "\n",
    "        # Visualization of residuals\n",
    "        viz = residuals_plot(pipe, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-05T16:49:31.306Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_algos_pipeline (train_set_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todos\n",
    "\n",
    "- different scalers\n",
    "- different encoder?\n",
    "- gridsearch\n",
    "- features importances --> feature engineering and adjustments to dataset --> recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
